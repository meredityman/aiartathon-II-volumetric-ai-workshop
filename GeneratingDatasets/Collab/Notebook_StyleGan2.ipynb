{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Notebook_StyleGan2",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meredityman/aiartathon-II-volumetric-ai-workshop/blob/main/GeneratingDatasets/Collab/Notebook_StyleGan2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEx9IOnF1hKO"
      },
      "source": [
        "#Training StyleGAN2 on Colab\n",
        "Yâ€™all wonâ€™t stop asking me about this so here ya go ðŸ˜‚\n",
        "\n",
        "If it were me Iâ€™d sign up for Colab Pro ($10/month) to get a couple extra hours of training time in per session. But you crazy kids can do whatever you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBYQ6_RFBuuq"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcDHP4h-11Ii"
      },
      "source": [
        "##Mounting Google Drive\n",
        "So Iâ€™m actually gonna install my entire repo directly into Google Drive. This will make the setup a little easier, but its a little strange I admit.\n",
        "\n",
        "First, connect your Drive to Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJazuNYurryY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aadrbMyR2F00"
      },
      "source": [
        "##Install the repo\n",
        "**Only do this for the first time ever setting this up!**\n",
        "\n",
        "If this is your first time ever running this notebook, youâ€™ll want to install my fork of StyleGAN2 to your Drive account. Make sure you have ample space on your Drive (Iâ€™d say at least 50GB). This will install the repo and add some dependecies (like transferring from FFHQ the first time).\n",
        "\n",
        "Every time after your first use of this notebook youâ€™ll want to skip this cell and run the cell after this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoTNQ3Gyr0ih"
      },
      "source": [
        "#SKIP this if you already have a stylegan2 folder in your google drive\n",
        "%cd /content/drive/My\\ Drive/\n",
        "!mkdir stylegan2-colab\n",
        "%cd stylegan2-colab/\n",
        "!git clone https://github.com/dvschultz/stylegan2\n",
        "%cd stylegan2\n",
        "!mkdir pkl\n",
        "%cd pkl\n",
        "!gdown --id 1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF #inception: https://drive.google.com/open?id=1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF\n",
        "%cd ../\n",
        "!mkdir results\n",
        "!mkdir results/00001-pretrained\n",
        "%cd results/00001-pretrained\n",
        "!gdown --id 1UlDmJVLLnBD9SnLSMXeiZRO6g-OMQCA_\n",
        "!mv stylegan2-ffhq-config-f.pkl network-snapshot-10000.pkl\n",
        "%cd ../../\n",
        "%mkdir datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN2K68CE27py"
      },
      "source": [
        "##Picking up from a previous session\n",
        "If you already have the StyleGAN2 repo installed in Drive skip the above cell and run the following. This will make sure you have the latest version in case I make updates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8WgjhRFsFJ0"
      },
      "source": [
        "#USE this if you already have a stylegan2 folder in google drive\n",
        "%cd /content/drive/My\\ Drive/stylegan2-colab/stylegan2\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSbEY2pT3TOb"
      },
      "source": [
        "##Make sure Tensorflow 1.15 is set\n",
        "Colab now defaults to Tensorflow 2. Make sure you run this cell to reset it to TF1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMdpKY1XODz2"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1pIBZGzZxSA"
      },
      "source": [
        "##Converting your dataset\n",
        "StyleGAN requires you to convert your standard jpg or png images into a new format (.tfrecords). \n",
        "\n",
        "Iâ€™ve seen some recommendations to run this command every time you restart your Colab machine. I think if you ahve a small-ish dataset (< 2000 images) thatâ€™s probably unnecessary.\n",
        "\n",
        "I recommend you upload your dataset to Google Drive and copy its path from the Drive folder in Colab and paste its path in the below cell.\n",
        "\n",
        "After the `create_from_images` argument you need to pass in two paths. The first path is where the .tfrecords files should be output (just edit the last part to have a unique name). The second path is to the directory of your images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixjcx2-cbTDm"
      },
      "source": [
        "#2nd argument is where to put your tfrecords files\n",
        "#3rd should point at your image dataset\n",
        "raw_data_path = '\"./datasets/trees-raw/Renders\"'\n",
        "!python dataset_tool.py create_from_images ./datasets/trees $raw_data_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAfUNG60aRD1"
      },
      "source": [
        "##Training\n",
        "Note: this will require you to restart your Colab machine every 8â€“16 hours. Youâ€™ve been warned!\n",
        "\n",
        "This library is set up to automatically find your latest .pkl file so it should keep re-training and making progress.\n",
        "\n",
        "##Training Options\n",
        "`--dataset`\n",
        "\n",
        "This should be the name you used in the first path when converting your dataset.\n",
        "\n",
        "`--mirror-augment`\n",
        "\n",
        "Using this option loads some images at random mirrored horizontally (left-to-right). This might help if you have a very small dataset.\n",
        "\n",
        "`--metrics`\n",
        "\n",
        "METRICS DONâ€™T MATTER. Itâ€™s art! Use your eyes. Set `--metrics=None` and live your life.\n",
        "\n",
        "If you must use metrics, you have a few options. `fid50k`, the default, uses Frechet Inception Distance score. Itâ€™s what was used in StyleGAN1 and what most people know. Itâ€™s fine for images of animals and things, but itâ€™s not great. `ppl_wend` is what StyleGAN2 prefers and claims to be more accurate. There are a bunch of other options but Iâ€™d recommend you stick with those. Note that both of these take 30â€“45minutes to run every time it runs so that cuts into your training time in Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn6AVoWP-6FK"
      },
      "source": [
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8QrOVqEHaipA"
      },
      "source": [
        "!python run_training.py --num-gpus=1 --data-dir=./datasets --config=config-f --dataset=trees --mirror-augment=true --metrics=None --resume_pkl='none'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ7U1ftuj_Dc"
      },
      "source": [
        "Once running, your training files will show up in the results folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9vCDt9LRtXl"
      },
      "source": [
        "#Testing the model (generating images)\n",
        "The following command will generate 55 sample images from the model.\n",
        "\n",
        "##Options\n",
        "`--network`\n",
        "\n",
        "Make sure the `--network` argument points to your .pkl file. (My preferred method is to right click on the file in the Files pane to your left and choose `Copy Path`, then paste that into the argument after the `=` sign).\n",
        "\n",
        "`--seeds`\n",
        "\n",
        "This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation.\n",
        "\n",
        "`--truncation-psi`\n",
        "\n",
        "Truncation is a special argument of StyleGAN. Essentially values that are closer to 0 will be more real than numbers further away from 0. I generally recommend a value between `0.5` and `1.0`. `0.5` will give you pretty \"realistic\" results, while `1.0` is likely to give you \"weirder\" results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3MhXEAMOMXH"
      },
      "source": [
        "!python run_generator.py generate-images --network=/content/ladiesfloralcrop-network-snapshot-010237.pkl --seeds=3875451-3876000 --truncation-psi=0.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMiqkA3IReZB"
      },
      "source": [
        "Letâ€™s zip the generated files and download them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp8O01O3PlFx"
      },
      "source": [
        "!zip -r generated-0.7.zip /content/stylegan2/results/00000-generate-images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTwJjmCrlfAc"
      },
      "source": [
        "##Interpolation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ2rYIC4TdaJ"
      },
      "source": [
        "!python run_generator.py generate-latent-walk --network=/content/ladiesfloralcrop-network-snapshot-010237.pkl --seeds=3,11,17,25,3 --frames 200 --truncation-psi=0.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dceBSxTsmW1H"
      },
      "source": [
        "#convert to video \n",
        "!ffmpeg -r 24 -i ./results/00001-generate-latent-walk/step%05d.png -vcodec libx264 -pix_fmt yuv420p latent-walk-v2.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7A7jRRGmzhU"
      },
      "source": [
        "rm -r /content/drive/My Drive/stylegan2-colab-test/stylegan2/results/00002-stylegan2-birdaus-1gpu-config-f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9UpP_fVdql9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}