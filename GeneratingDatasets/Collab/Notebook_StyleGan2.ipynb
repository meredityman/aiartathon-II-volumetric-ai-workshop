{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook_StyleGan2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meredityman/aiartathon-II-volumetric-ai-workshop/blob/main/GeneratingDatasets/Collab/Notebook_StyleGan2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEx9IOnF1hKO"
      },
      "source": [
        "#Training StyleGAN2 on Colab\n",
        "Yâ€™all wonâ€™t stop asking me about this so here ya go ðŸ˜‚\n",
        "\n",
        "If it were me Iâ€™d sign up for Colab Pro ($10/month) to get a couple extra hours of training time in per session. But you crazy kids can do whatever you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBYQ6_RFBuuq",
        "outputId": "07200a38-5c9b-4c1e-c6a7-26c7dc0d8613"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct 31 15:45:52 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.29.05    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcDHP4h-11Ii"
      },
      "source": [
        "##Mounting Google Drive\n",
        "So Iâ€™m actually gonna install my entire repo directly into Google Drive. This will make the setup a little easier, but its a little strange I admit.\n",
        "\n",
        "First, connect your Drive to Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJazuNYurryY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a147bd8e-7559-44c0-9ee8-929c9653d9c6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aadrbMyR2F00"
      },
      "source": [
        "##Install the repo\n",
        "**Only do this for the first time ever setting this up!**\n",
        "\n",
        "If this is your first time ever running this notebook, youâ€™ll want to install my fork of StyleGAN2 to your Drive account. Make sure you have ample space on your Drive (Iâ€™d say at least 50GB). This will install the repo and add some dependecies (like transferring from FFHQ the first time).\n",
        "\n",
        "Every time after your first use of this notebook youâ€™ll want to skip this cell and run the cell after this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoTNQ3Gyr0ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d903be3b-f3fb-4ed1-90d1-43424a836355"
      },
      "source": [
        "#SKIP this if you already have a stylegan2 folder in your google drive\n",
        "%cd /content/drive/My\\ Drive/\n",
        "!mkdir stylegan2-colab\n",
        "%cd stylegan2-colab/\n",
        "!git clone https://github.com/dvschultz/stylegan2\n",
        "%cd stylegan2\n",
        "!mkdir pkl\n",
        "%cd pkl\n",
        "!gdown --id 1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF #inception: https://drive.google.com/open?id=1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF\n",
        "%cd ../\n",
        "!mkdir results\n",
        "!mkdir results/00001-pretrained\n",
        "%cd results/00001-pretrained\n",
        "!gdown --id 1UlDmJVLLnBD9SnLSMXeiZRO6g-OMQCA_\n",
        "!mv stylegan2-ffhq-config-f.pkl network-snapshot-10000.pkl\n",
        "%cd ../../\n",
        "%mkdir datasets"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n",
            "mkdir: cannot create directory â€˜stylegan2-colabâ€™: File exists\n",
            "/content/drive/My Drive/stylegan2-colab\n",
            "fatal: destination path 'stylegan2' already exists and is not an empty directory.\n",
            "/content/drive/My Drive/stylegan2-colab/stylegan2\n",
            "mkdir: cannot create directory â€˜pklâ€™: File exists\n",
            "/content/drive/My Drive/stylegan2-colab/stylegan2/pkl\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF\n",
            "To: /content/drive/My Drive/stylegan2-colab/stylegan2/pkl/inception_v3_features.pkl\n",
            "100% 87.3M/87.3M [00:01<00:00, 46.7MB/s]\n",
            "/content/drive/My Drive/stylegan2-colab/stylegan2\n",
            "mkdir: cannot create directory â€˜resultsâ€™: File exists\n",
            "mkdir: cannot create directory â€˜results/00001-pretrainedâ€™: File exists\n",
            "/content/drive/My Drive/stylegan2-colab/stylegan2/results/00001-pretrained\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UlDmJVLLnBD9SnLSMXeiZRO6g-OMQCA_\n",
            "To: /content/drive/My Drive/stylegan2-colab/stylegan2/results/00001-pretrained/stylegan2-ffhq-config-f.pkl\n",
            "100% 382M/382M [00:03<00:00, 124MB/s]\n",
            "/content/drive/My Drive/stylegan2-colab/stylegan2\n",
            "mkdir: cannot create directory â€˜datasetsâ€™: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN2K68CE27py"
      },
      "source": [
        "##Picking up from a previous session\n",
        "If you already have the StyleGAN2 repo installed in Drive skip the above cell and run the following. This will make sure you have the latest version in case I make updates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8WgjhRFsFJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0d362e-30d2-439c-b637-258a73b96b55"
      },
      "source": [
        "#USE this if you already have a stylegan2 folder in google drive\n",
        "%cd /content/drive/My\\ Drive/stylegan2-colab/stylegan2\n",
        "!git pull"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/stylegan2-colab/stylegan2\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSbEY2pT3TOb"
      },
      "source": [
        "##Make sure Tensorflow 1.15 is set\n",
        "Colab now defaults to Tensorflow 2. Make sure you run this cell to reset it to TF1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMdpKY1XODz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1efad72-5763-490e-8506-8fa2f299301e"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1pIBZGzZxSA"
      },
      "source": [
        "##Converting your dataset\n",
        "StyleGAN requires you to convert your standard jpg or png images into a new format (.tfrecords). \n",
        "\n",
        "Iâ€™ve seen some recommendations to run this command every time you restart your Colab machine. I think if you ahve a small-ish dataset (< 2000 images) thatâ€™s probably unnecessary.\n",
        "\n",
        "I recommend you upload your dataset to Google Drive and copy its path from the Drive folder in Colab and paste its path in the below cell.\n",
        "\n",
        "After the `create_from_images` argument you need to pass in two paths. The first path is where the .tfrecords files should be output (just edit the last part to have a unique name). The second path is to the directory of your images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixjcx2-cbTDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279a8754-6bec-48c9-d8e3-1a252cbb4112"
      },
      "source": [
        "#2nd argument is where to put your tfrecords files\n",
        "#3rd should point at your image dataset\n",
        "raw_data_path = '\"./datasets/trees-raw/Renders\"'\n",
        "!python dataset_tool.py create_from_images ./datasets/trees $raw_data_path"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images from \"./datasets/trees-raw/Renders\"\n",
            "  0% 0/800 [00:00<?, ?it/s]dataset_tool.py:87: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
            "100% 800/800 [04:41<00:00,  2.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAfUNG60aRD1"
      },
      "source": [
        "##Training\n",
        "Note: this will require you to restart your Colab machine every 8â€“16 hours. Youâ€™ve been warned!\n",
        "\n",
        "This library is set up to automatically find your latest .pkl file so it should keep re-training and making progress.\n",
        "\n",
        "##Training Options\n",
        "`--dataset`\n",
        "\n",
        "This should be the name you used in the first path when converting your dataset.\n",
        "\n",
        "`--mirror-augment`\n",
        "\n",
        "Using this option loads some images at random mirrored horizontally (left-to-right). This might help if you have a very small dataset.\n",
        "\n",
        "`--metrics`\n",
        "\n",
        "METRICS DONâ€™T MATTER. Itâ€™s art! Use your eyes. Set `--metrics=None` and live your life.\n",
        "\n",
        "If you must use metrics, you have a few options. `fid50k`, the default, uses Frechet Inception Distance score. Itâ€™s what was used in StyleGAN1 and what most people know. Itâ€™s fine for images of animals and things, but itâ€™s not great. `ppl_wend` is what StyleGAN2 prefers and claims to be more accurate. There are a bunch of other options but Iâ€™d recommend you stick with those. Note that both of these take 30â€“45minutes to run every time it runs so that cuts into your training time in Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn6AVoWP-6FK",
        "outputId": "80d08ccc-fa70-4a31-9c62-051300cede68"
      },
      "source": [
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU says hello.\n",
            "GPU says hello.\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-584a5b7d-12b0-716b-e606-96e407b2dd46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QrOVqEHaipA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "056f0287-5516-42de-ed9f-2f95a686a3b8"
      },
      "source": [
        "!python run_training.py --num-gpus=1 --data-dir=./datasets --config=config-f --dataset=trees --mirror-augment=true --metrics=None --resume_pkl='none'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couldn't find valid snapshot, starting over\n",
            "Local submit - run_dir: results/00007-stylegan2-trees-1gpu-config-f\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55fb39372000 @  0x7f6bb6ffd001 0x7f6bb3ae154f 0x7f6bb3b31b58 0x7f6bb3b35b17 0x7f6bb3bd4203 0x55fb31f87544 0x55fb31f87240 0x55fb31ffb627 0x55fb31ff5ced 0x55fb31f8948c 0x55fb31fca159 0x55fb31fc70a4 0x55fb31f89698 0x55fb31ff7fe4 0x55fb31ff59ee 0x55fb31ec7e2b 0x55fb31ff7fe4 0x55fb31ff59ee 0x55fb31ec7e2b 0x55fb31ff7fe4 0x55fb31f88afa 0x55fb31ff6915 0x55fb31f88afa 0x55fb31ff6c0d 0x55fb31ff59ee 0x55fb31ec7e2b 0x55fb31ff7fe4 0x55fb31ff59ee 0x55fb31ec7e2b 0x55fb31ff7fe4 0x55fb31f88afa\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55fc39372000 @  0x7f6bb6ffb1e7 0x7f6bb3ae146e 0x7f6bb3b31c7b 0x7f6bb3b3235f 0x7f6bb3bd4103 0x55fb31f87544 0x55fb31f87240 0x55fb31ffb627 0x55fb31ff59ee 0x55fb31f88bda 0x55fb31ff7737 0x55fb31ff59ee 0x55fb31f88bda 0x55fb31ff7737 0x55fb31ff59ee 0x55fb31f88bda 0x55fb31ff7737 0x55fb31f88afa 0x55fb31ff6915 0x55fb31ff59ee 0x55fb31f88bda 0x55fb31ffad00 0x55fb31ff59ee 0x55fb31f88bda 0x55fb31ff7737 0x55fb31ff5ced 0x55fb31f8948c 0x55fb31fca159 0x55fb31fc70a4 0x55fb31f89698 0x55fb31ff7fe4\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x55fd3ab12000 @  0x7f6bb6ffb1e7 0x7f6bb3ae146e 0x7f6bb3b31c7b 0x7f6bb3b3235f 0x7f6b5d042235 0x7f6b5c9c5792 0x7f6b5c9c5d42 0x7f6b5c97eaee 0x55fb31f87437 0x55fb31f87240 0x55fb31ffb0f3 0x55fb31f88afa 0x55fb31ff6c0d 0x55fb31ff5ced 0x55fb31ec7eb0 0x55fb31ff7fe4 0x55fb31ff59ee 0x55fb31f88bda 0x55fb31ff6c0d 0x55fb31ff5ced 0x55fb31f88bda 0x55fb31ff6c0d 0x55fb31f88afa 0x55fb31ff6c0d 0x55fb31ff59ee 0x55fb31f89271 0x55fb31f89698 0x55fb31ff7fe4 0x55fb31ff59ee 0x55fb31f88bda 0x55fb31ff6915\n",
            "Dataset shape = [3, 512, 512]\n",
            "Dynamic range = [0, 255]\n",
            "Label size    = 0\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n",
            "\n",
            "G                             Params    OutputShape         WeightShape     \n",
            "---                           ---       ---                 ---             \n",
            "latents_in                    -         (?, 512)            -               \n",
            "labels_in                     -         (?, 0)              -               \n",
            "lod                           -         ()                  -               \n",
            "dlatent_avg                   -         (512,)              -               \n",
            "G_mapping/latents_in          -         (?, 512)            -               \n",
            "G_mapping/labels_in           -         (?, 0)              -               \n",
            "G_mapping/Normalize           -         (?, 512)            -               \n",
            "G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n",
            "G_mapping/Broadcast           -         (?, 16, 512)        -               \n",
            "G_mapping/dlatents_out        -         (?, 16, 512)        -               \n",
            "Truncation/Lerp               -         (?, 16, 512)        -               \n",
            "G_synthesis/dlatents_in       -         (?, 16, 512)        -               \n",
            "G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB         264195    (?, 3, 4, 4)        (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample      -         (?, 3, 8, 8)        -               \n",
            "G_synthesis/8x8/ToRGB         264195    (?, 3, 8, 8)        (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample    -         (?, 3, 16, 16)      -               \n",
            "G_synthesis/16x16/ToRGB       264195    (?, 3, 16, 16)      (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample    -         (?, 3, 32, 32)      -               \n",
            "G_synthesis/32x32/ToRGB       264195    (?, 3, 32, 32)      (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample    -         (?, 3, 64, 64)      -               \n",
            "G_synthesis/64x64/ToRGB       264195    (?, 3, 64, 64)      (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample  -         (?, 3, 128, 128)    -               \n",
            "G_synthesis/128x128/ToRGB     132099    (?, 3, 128, 128)    (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample  -         (?, 3, 256, 256)    -               \n",
            "G_synthesis/256x256/ToRGB     66051     (?, 3, 256, 256)    (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up  139457    (?, 64, 512, 512)   (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1     69761     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample  -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/512x512/ToRGB     33027     (?, 3, 512, 512)    (1, 1, 64, 3)   \n",
            "G_synthesis/images_out        -         (?, 3, 512, 512)    -               \n",
            "G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n",
            "G_synthesis/noise1            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n",
            "G_synthesis/noise3            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n",
            "G_synthesis/noise5            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n",
            "G_synthesis/noise7            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n",
            "G_synthesis/noise9            -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n",
            "G_synthesis/noise11           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n",
            "G_synthesis/noise13           -         (1, 1, 512, 512)    -               \n",
            "G_synthesis/noise14           -         (1, 1, 512, 512)    -               \n",
            "images_out                    -         (?, 3, 512, 512)    -               \n",
            "---                           ---       ---                 ---             \n",
            "Total                         30276583                                      \n",
            "\n",
            "\n",
            "D                    Params    OutputShape         WeightShape     \n",
            "---                  ---       ---                 ---             \n",
            "images_in            -         (?, 3, 512, 512)    -               \n",
            "labels_in            -         (?, 0)              -               \n",
            "512x512/FromRGB      256       (?, 64, 512, 512)   (1, 1, 3, 64)   \n",
            "512x512/Conv0        36928     (?, 64, 512, 512)   (3, 3, 64, 64)  \n",
            "512x512/Conv1_down   73856     (?, 128, 256, 256)  (3, 3, 64, 128) \n",
            "512x512/Skip         8192      (?, 128, 256, 256)  (1, 1, 64, 128) \n",
            "256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n",
            "256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n",
            "256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n",
            "128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n",
            "128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n",
            "128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n",
            "64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n",
            "64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n",
            "32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n",
            "32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n",
            "16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n",
            "16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n",
            "8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n",
            "8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n",
            "8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n",
            "4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n",
            "4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n",
            "Output               513       (?, 1)              (512, 1)        \n",
            "scores_out           -         (?, 1)              -               \n",
            "---                  ---       ---                 ---             \n",
            "Total                28982849                                      \n",
            "\n",
            "Building TensorFlow graph...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 10000.1  lod 0.00  minibatch 32   time 56s          sec/tick 56.2    sec/kimg 438.77  maintenance 0.0    gpumem 6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ7U1ftuj_Dc"
      },
      "source": [
        "Once running, your training files will show up in the results folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9vCDt9LRtXl"
      },
      "source": [
        "#Testing the model (generating images)\n",
        "The following command will generate 55 sample images from the model.\n",
        "\n",
        "##Options\n",
        "`--network`\n",
        "\n",
        "Make sure the `--network` argument points to your .pkl file. (My preferred method is to right click on the file in the Files pane to your left and choose `Copy Path`, then paste that into the argument after the `=` sign).\n",
        "\n",
        "`--seeds`\n",
        "\n",
        "This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation.\n",
        "\n",
        "`--truncation-psi`\n",
        "\n",
        "Truncation is a special argument of StyleGAN. Essentially values that are closer to 0 will be more real than numbers further away from 0. I generally recommend a value between `0.5` and `1.0`. `0.5` will give you pretty \"realistic\" results, while `1.0` is likely to give you \"weirder\" results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3MhXEAMOMXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f3fd4e-7d76-421e-8b24-ec1d1ebb3ac1"
      },
      "source": [
        "!python run_generator.py generate-images --network=/content/ladiesfloralcrop-network-snapshot-010237.pkl --seeds=3875451-3876000 --truncation-psi=0.7"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"run_generator.py\", line 16, in <module>\n",
            "    from opensimplex import OpenSimplex\n",
            "ModuleNotFoundError: No module named 'opensimplex'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMiqkA3IReZB"
      },
      "source": [
        "Letâ€™s zip the generated files and download them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp8O01O3PlFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f31a896-6b98-4338-aaa6-699c5fa57486"
      },
      "source": [
        "!zip -r generated-0.7.zip /content/stylegan2/results/00000-generate-images"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: /content/stylegan2/results/00000-generate-images\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r generated-0.7.zip . -i /content/stylegan2/results/00000-generate-images)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTwJjmCrlfAc"
      },
      "source": [
        "##Interpolation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ2rYIC4TdaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a56f38-0017-4ba6-e027-60ea76cd969a"
      },
      "source": [
        "!python run_generator.py generate-latent-walk --network=/content/ladiesfloralcrop-network-snapshot-010237.pkl --seeds=3,11,17,25,3 --frames 200 --truncation-psi=0.7"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"run_generator.py\", line 16, in <module>\n",
            "    from opensimplex import OpenSimplex\n",
            "ModuleNotFoundError: No module named 'opensimplex'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dceBSxTsmW1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452da12f-55d9-4703-8507-26fb1c5cd14d"
      },
      "source": [
        "#convert to video \n",
        "!ffmpeg -r 24 -i ./results/00001-generate-latent-walk/step%05d.png -vcodec libx264 -pix_fmt yuv420p latent-walk-v2.mp4"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "\u001b[0;35m[image2 @ 0x55e047a30000] \u001b[0m\u001b[1;31mCould find no file with path './results/00001-generate-latent-walk/step%05d.png' and index in the range 0-4\n",
            "\u001b[0m\u001b[1;31m./results/00001-generate-latent-walk/step%05d.png: No such file or directory\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7A7jRRGmzhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842d508f-4917-40e1-d6ba-8e10f44809d8"
      },
      "source": [
        "rm -r /content/drive/My Drive/stylegan2-colab-test/stylegan2/results/00002-stylegan2-birdaus-1gpu-config-f"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/drive/My': No such file or directory\n",
            "rm: cannot remove 'Drive/stylegan2-colab-test/stylegan2/results/00002-stylegan2-birdaus-1gpu-config-f': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9UpP_fVdql9"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}